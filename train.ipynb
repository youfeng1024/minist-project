{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\youfeng\\miniconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from model.cnn import CNN\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "MODEL = 'CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5373952/26421880 [00:12<00:56, 370986.41it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# load training sets, split the dataset into training and validation sets\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "trainset, valset = data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "trainloader = data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "valloader = data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# load test set\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the CNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if MODEL == 'CNN':\n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self, INPUT_CHANNELS : int, NUM_CLASSES : int):\n",
    "            super(CNN, self).__init__()\n",
    "            self.cnnBlock1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=INPUT_CHANNELS, out_channels=32, \n",
    "                        kernel_size=3, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(32),  # Add batch normalization layer\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.cnnBlock2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, \n",
    "                        kernel_size=3, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(64),  # Add batch normalization layer\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.cnnBlock3 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, \n",
    "                        kernel_size=3, stride=1, padding='same'),\n",
    "                nn.BatchNorm2d(128),  # Add batch normalization layer\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.fc1 = nn.LazyLinear(out_features=128)\n",
    "            self.fc2 = nn.LazyLinear(out_features=NUM_CLASSES)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.cnnBlock1(x)\n",
    "            x = self.cnnBlock2(x)\n",
    "            x = self.cnnBlock3(x)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            x = F.relu(self.fc1(x)) \n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "else:\n",
    "    raise ValueError('Model not supported: {}'.format(MODEL))\n",
    "\n",
    "net = CNN(INPUT_CHANNELS=1, NUM_CLASSES=10).to(device)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Define the loss function, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the model\n",
    "num_epochs = EPOCHS\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "best_val_acc = 0.0  # 用于跟踪最佳验证准确率\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_total = 0\n",
    "    val_total = 0\n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    # Training\n",
    "    net.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_loss /= len(trainloader)\n",
    "    val_loss /= len(valloader)\n",
    "    train_acc = 100.0 * train_correct / train_total\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # 保存最佳模型\n",
    "    best_model_path = f\"./checkpoints/{MODEL}_acc={val_accs}.pth\"\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(net.state_dict(), best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Plot the training process\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), train_accs, label='Train')\n",
    "plt.plot(range(1, num_epochs+1), val_accs, label='Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model on the test set\n",
    "test_total = 0\n",
    "test_correct = 0\n",
    "\n",
    "net.load_state_dict(torch.load(best_model_path))\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "test_acc = 100.0 * test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
