
# 分布式算法实验

# 实验要求：
使用全连接网络、CNN网络、RNN网络、注意力RNN网络4种模型，实现图像识别（不要用示例代码的手写体数据集），完成以下功能，并编写实现报告：

# 实验配置
- 环境：Python3.11
- windows10笔记本电脑：无GPU
- IDE：vscode
- pytorch
- 数据集：FashionMNIST

# 一、模型定义
实验所用到的四个模型分别是全连接网络、CNN网络、RNN网络、注意力RNN网络，下面分别介绍这四个模型的实现与具体结构。
## MLP
### MLP的代码实现
通过nn.Sequential，实现了一个通过传入列表可定义任意深度的全连接网络。
```py
class MLP(nn.Module):
    def __init__(self, layer_dims: list[int]):
        super(MLP, self).__init__()
        layers = []
        for i in range(len(layer_dims) - 1):
            layers.append(nn.Linear(layer_dims[i], layer_dims[i + 1]))
            if i < len(layer_dims) - 2:  # 最后一层不需要激活函数
                layers.append(nn.ReLU())
                layers.append(nn.Dropout(0.1))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        x = x.reshape(x.size(0), -1)  # 展平输入
        return self.network(x)
```
### 实验MLP的具体结构与参数

```
MLP(
  (network): Sequential(
    (0): Linear(in_features=784, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=256, out_features=64, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.1, inplace=False)
    (6): Linear(in_features=64, out_features=10, bias=True)
  )
)
```

## CNN
### CNN的代码实现
```py
class CNN(nn.Module):
    def __init__(self, input_channels : int, output_size : int):
        super(CNN, self).__init__()
        self.cnnBlock1 = nn.Sequential(
            nn.Conv2d(in_channels=input_channels, out_channels=32, 
                    kernel_size=3, stride=1, padding='same'),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.cnnBlock2 = nn.Sequential(
            nn.Conv2d(in_channels=32, out_channels=128, 
                    kernel_size=3, stride=1, padding='same'),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.fc1 = nn.LazyLinear(out_features=128)
        self.fc2 = nn.LazyLinear(out_features=output_size)

    def forward(self, x) :
        x = self.cnnBlock1(x)
        x = self.cnnBlock2(x)
        x = x.reshape(x.shape[0], -1)
        x = F.relu(self.fc1(x)) 
        x = self.fc2(x)
        return x
```

### 实验CNN的具体结构与参数
```
CNN(
  (cnnBlock1): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (cnnBlock2): Sequential(
    (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Linear(in_features=6272, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
```

## RNN
这里的RNN采用的是单层双向GRU。
### RNN的代码实现
```py
class RNN(nn.Module):
    def __init__(self, seq_len : int, output_size : int, 
                 hidden_size: int, num_layers: int):
        super(RNN, self).__init__()
        self.seq_len = seq_len
        self.hidden_size = hidden_size
        self.num_layers = num_layers     
        # 定义双层 RNN 层
        self.rnn = nn.GRU(self.seq_len, self.hidden_size, num_layers, 
                          dropout= 0.1 , bidirectional = True ,batch_first=True)    
        # 定义输出层
        self.fc = nn.Linear(2 * hidden_size, output_size)
    
    def forward(self, x):
        x = x.permute(0, 2, 3, 1).reshape(x.shape[0], self.seq_len, -1)
        out, _ = self.rnn(x, None)   
        # 取最后一个时间步的输出
        out = out[:, -1, :]
        # 通过全连接层得到最终输出
        out = self.fc(out)     
        return out
```
### 实验RNN的具体结构与参数
```
RNN(
  (rnn): GRU(28, 128, batch_first=True, dropout=0.1, bidirectional=True)
  (fc): Linear(in_features=256, out_features=10, bias=True)
)
```

## AttentionRNN
这里的RNN采用的是单层双向GRU。
### AttentionRNN的代码实现
```py
class RNN_ATTN(nn.Module):
    def __init__(self, input_size: int, hidden_size: int, output_size: int):
        super().__init__()
        self.input_size = input_size   
        self.bigru = nn.GRU(input_size, hidden_size, bidirectional=True, batch_first=True)        
        # 定义一个可学习的参数
        self.attn_weight = nn.Linear(2 * hidden_size, 1, bias=False)
        self.fc = nn.Linear(2 * hidden_size, output_size)
        
    def attention(self, key):             
        # 点积方式打分 计算概率分布
        weight = F.softmax(self.attn_weight(key), dim=1)
        value = key       
        out= torch.sum(weight * value, dim=1)
        # (batch, hidden_size) 
        return out
        
    def forward(self, X):
        """ out的形状：(batch, seq, feature) """
        X = X.permute(0, 2, 3, 1).reshape(X.shape[0], self.input_size, -1)
        out, _ = self.bigru(X)
        # 获得所有样本最后时刻的输出
        out = self.attention(out)       
        out = self.fc(out)    
        return out
```

### 实验AttentionRNN的具体结构与参数
```
RNN_ATTN(
  (bigru): GRU(28, 64, batch_first=True, bidirectional=True)
  (attn_weight): Linear(in_features=128, out_features=1, bias=False)
  (fc): Linear(in_features=128, out_features=10, bias=True)
)
```

# 二、模型训练与结果分析
在模型训练阶段，使用交叉验证，便于观察模型拟合情况和找出最优模型。代码首先初始化用于记录训练和验证损失及准确率的列表，并设置最佳验证准确率变量。在每一轮迭代中，模型首先切换到训练模式，处理训练数据集，计算损失并更新参数。然后，模型切换到验证模式，评估验证数据集的性能。每轮迭代结束时，记录训练和验证的损失及准确率，以便后续绘图和分析，并依据训练集准确度判断是否保存。

# 三、保存与加载


# 五、FLASK搭建模型推理API


# 六、实验对比

